# 欢迎来到MindSpore Transformer

## Progressively Stacking Train

### 算法介绍

### 使用
```shell
bash examples/pretrain/pretrain_stack_gpt.sh DEVICE_ID DATA_DIR
```
在脚本文件中新添加了如下两个参数：
- stages: 这个参数为Progressively Stacking Train时分为几个阶段进行模型的训练，例如[3,6,12]即先进行3层训练，然后3层权重叠加到6层进行训练，最后6层权重叠加到12层进行训练
- stage_epochs: 这个参数为Progressively Stacking Train时每个阶段训练的epochs数量，例如[1,1,3]即3层模型训练1个epoch，接着6层模型训练1个epoch，最后12层模型训练3个epoch

### 训练日志
此接口代码有一个示例日志，为训练日志.txt，为GPT模型在小数据集上进行训练的日志文件。
